{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgimxfrKVa35rklCNJzV5M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sana-Harshitha/LLMPractice/blob/main/LLMSimpleTokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hFB2QdRHFrm",
        "outputId": "b9e55f12-6f5f-40b9-faa9-280fc5b716ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('the-verdict.txt', <http.client.HTTPMessage at 0x7ba7143dcb50>)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import urllib.request\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        "\"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        "\"the-verdict.txt\")\n",
        "file_path = \"the-verdict.txt\"\n",
        "urllib.request.urlretrieve(url, file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "   raw_text = f.read()\n",
        "print(\"Total number of character:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI4SLR7pIlX3",
        "outputId": "576780c4-9d7c-47e7-91d2-c55d90fafde4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of character: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spliting the rawText"
      ],
      "metadata": {
        "id": "DOb2tBf4Pzy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "preprocessed=re.split(r'([,.:;?_!\"()\\']|--|\\s)',raw_text)\n",
        "result = [item.strip() for item in preprocessed if item.strip()]\n",
        "print(len(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EerhmGCyI32D",
        "outputId": "ced15072-ac13-4ef2-c449-2f9daddfe563"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Vocabulary dict for raw text"
      ],
      "metadata": {
        "id": "__EdaDgvLnNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting all Unique sorted words\n",
        "all_tokens = sorted(set(preprocessed))\n",
        "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"]) #includeing tokens for endofdoc and unknown words\n",
        "vocab_size = len(all_tokens)\n",
        "print('Vocabulary_size:',vocab_size)\n",
        "all_tokens[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFkln2sbJpG9",
        "outputId": "eba5b832-20d4-453f-b3cc-30db804d783f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary_size: 1135\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '--',\n",
              " '.',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'Ah',\n",
              " 'Among',\n",
              " 'And',\n",
              " 'Are',\n",
              " 'Arrt']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
        "for i, item in enumerate(vocab.items()):\n",
        "   print(item)\n",
        "   if i >= 20:\n",
        "      break\n",
        "print(20*\"-\")\n",
        "for i, item in enumerate(list(vocab.items())[-5:]):\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeb7rMZUL6nD",
        "outputId": "c185a406-9aeb-4236-eda6-7d7257e0b7a4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('', 0)\n",
            "('\\n', 1)\n",
            "(' ', 2)\n",
            "('!', 3)\n",
            "('\"', 4)\n",
            "(\"'\", 5)\n",
            "('(', 6)\n",
            "(')', 7)\n",
            "(',', 8)\n",
            "('--', 9)\n",
            "('.', 10)\n",
            "(':', 11)\n",
            "(';', 12)\n",
            "('?', 13)\n",
            "('A', 14)\n",
            "('Ah', 15)\n",
            "('Among', 16)\n",
            "('And', 17)\n",
            "('Are', 18)\n",
            "('Arrt', 19)\n",
            "('As', 20)\n",
            "--------------------\n",
            "('younger', 1130)\n",
            "('your', 1131)\n",
            "('yourself', 1132)\n",
            "('<|endoftext|>', 1133)\n",
            "('<|unk|>', 1134)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizer:\n",
        "     def __init__(self, vocab):\n",
        "          self.str_to_int = vocab\n",
        "          self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "     def encode(self, text):\n",
        "          preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
        "          preprocessed = [\n",
        "                     item.strip() for item in preprocessed if item.strip()\n",
        "                         ]\n",
        "          preprocessed = [item if item in self.str_to_int\n",
        "                          else \"<|unk|>\" for item in preprocessed]\n",
        "          ids = [self.str_to_int[s] for s in preprocessed]\n",
        "          return ids\n",
        "     def decode(self, ids):\n",
        "          text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "          text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)  #Replaces spacesbefore the specified punctuations\n",
        "          return text"
      ],
      "metadata": {
        "id": "8ajWJ_FjNGFe"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizer(vocab)\n",
        "text = \"\"\"\"It's the last he painted, you know,\"\n",
        "Mrs. Gisburn said with pardonable pride. Hello\"\"\"\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFMKhbO8N7df",
        "outputId": "5c14e17d-7149-41fd-cd3f-74c96599977e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 59, 5, 853, 991, 605, 536, 749, 8, 1129, 599, 8, 4, 70, 10, 41, 854, 1111, 757, 796, 10, 1134]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_output=tokenizer.decode(ids)\n",
        "text_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3dnbMiT8O2j8",
        "outputId": "370800a2-0a65-46de-af96-b663f065ac9d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride. <|unk|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets see how it handles unknown words"
      ],
      "metadata": {
        "id": "tNl3h_mURqoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"Hello, do you like tea?\"\n",
        "text2 = \"In the sunlit terraces of the palace.\"\n",
        "text = \" <|endoftext|> \".join((text1, text2))\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pExZ2rrPBze",
        "outputId": "0fad3e07-1fb2-4918-977a-ab276482fe78"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizer(vocab)\n",
        "print(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-G4veSCRTv2",
        "outputId": "1c528710-5ac4-4ec7-d359-e147c81d03b6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1134, 8, 358, 1129, 631, 978, 13, 1133, 58, 991, 959, 987, 725, 991, 1134, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(tokenizer.encode(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn8w2MUPReXW",
        "outputId": "f53e8d1b-4f40-4795-cae3-2c3c8a4458ed"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZWbOfCGvRmpK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}