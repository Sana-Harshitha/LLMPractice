{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sana-Harshitha/LLMPractice/blob/main/Training_LLm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VUjBBZ4_Su-_"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Cpwka5gty2C0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZQ_nySSSMZ3",
        "outputId": "1d1a8bc1-88e4-4afc-9d56-c8a7ca986dfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('the-verdict.txt', <http.client.HTTPMessage at 0x7e26a2138ad0>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        "\"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        "\"the-verdict.txt\")\n",
        "file_path = \"the-verdict.txt\"\n",
        "urllib.request.urlretrieve(url, file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTihTmowSW4J",
        "outputId": "eccac572-5353-45b9-b804-fd1b4902457b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of character: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ],
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print(\"Total number of character:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iQMf8zDSSdtt"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 256, # Context length\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qga6IdUhWj8P"
      },
      "source": [
        "#Creating input-target pairs for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xuV9YWYPTDpJ"
      },
      "outputs": [],
      "source": [
        "class GPTDatasetV1(Dataset):\n",
        "   def __init__(self, txt, tokenizer, max_length, stride):\n",
        "         self.input_ids = []\n",
        "         self.target_ids = []\n",
        "         token_ids = tokenizer.encode(txt)\n",
        "         for i in range(0, len(token_ids) - max_length, stride):\n",
        "              input_chunk = token_ids[i:i + max_length]\n",
        "              target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "              self.input_ids.append(torch.tensor(input_chunk))\n",
        "              self.target_ids.append(torch.tensor(target_chunk))\n",
        "   def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "   def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "          stride=128, shuffle=True, drop_last=True,\n",
        "          num_workers=0):\n",
        "          tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "          dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "          dataloader = DataLoader(\n",
        "                           dataset,\n",
        "                           batch_size=batch_size,\n",
        "                           shuffle=shuffle,\n",
        "                           drop_last=drop_last,\n",
        "                           num_workers=num_workers\n",
        "                                   )\n",
        "          return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "plzhqZ5PTvnl"
      },
      "outputs": [],
      "source": [
        "# Train/validation ratio\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(raw_text))\n",
        "train_data = raw_text[:split_idx]\n",
        "val_data = raw_text[split_idx:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oTdrGGLIUFvk"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b32BoCahW0Ec"
      },
      "source": [
        "#GPT2 Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSLP0nUwXF-g"
      },
      "source": [
        "Transformer Block:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EeoNxADiWVaW"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self,emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps=1e-6\n",
        "    self.scale=nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift=nn.Parameter(torch.zeros(emb_dim))\n",
        "  def forward(self,x):\n",
        "    mean=x.mean(dim=-1,keepdim=True)\n",
        "    var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "    norm_x=(x-mean)/torch.sqrt(var+self.eps)\n",
        "    return self.scale*norm_x+self.shift\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lBEQmINXNmJ"
      },
      "source": [
        "GPT2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3hapUwnSXEai"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QrTQmTWZXLum"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJYnzjCbXcfP"
      },
      "source": [
        "Next, we implement a utility function to calculate the cross-entropy loss of a given batch.\n",
        "\n",
        "In addition, we implement a second utility function to compute the loss for a user-specified number of batches in a data loader.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "W7_UmasEXUgF"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry-MMduxtXP4"
      },
      "source": [
        "## TRAINING LOOP FOR THE LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bo2g9muAtXP4"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMvYVPGYwcqm"
      },
      "source": [
        "Step 1: Initialize lists to track losses and tokens seen\n",
        "\n",
        "Step 2: Start the main training loop\n",
        "\n",
        "Step 3: Reset loss gradients from previous batch iteration\n",
        "\n",
        "Step 4: Calculate loss gradients\n",
        "\n",
        "Step 5: Update model weights using loss gradients\n",
        "\n",
        "Step 6: Optional evaluation step\n",
        "\n",
        "Step 7: Print a sample text after each epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "j_3oBVsAbFpu"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbmfXbWhtXP5"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "The evaluate_model function calculates the loss over the training and\n",
        "validation set while ensuring the model is in evaluation mode with gradient tracking and\n",
        "dropout disabled when calculating the loss over the training and validation sets\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jP3CbMelyCdD"
      },
      "outputs": [],
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bdDVaJFgygck"
      },
      "outputs": [],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "\n",
        "    ###Input batch:\n",
        " ###tensor([[6109, 3626, 6100,  345],\n",
        "        ##[6109, 1110, 6622,  257]])\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4YCWm_1ItXP6"
      },
      "outputs": [],
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9BQOCcbtXP6"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "The generate_and_print_sample function is a convenience function that we use to track whether the model improves during the training.\n",
        "\n",
        "In particular, the generate_and_print_sample function takes a text snippet (start_context) as input,\n",
        "converts it into token IDs, and feeds it to the LLM to generate a text sample using the\n",
        "generate_text_simple function we used earlier\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP7i5WnbtXP6"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's see this all in action by training a GPTModel instance for 10 epochs using an AdamW\n",
        "optimizer and the train_model_simple function we defined earlier.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cvXdk4NjypUO"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWYWn4ZCtXP6",
        "outputId": "40a165ae-25d9-4aa2-bb17-d86281dc01da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.783, Val loss 9.927\n",
            "Ep 1 (Step 000005): Train loss 7.985, Val loss 8.335\n",
            "Every effort moves you,,,,,,,,,,,,.                                     \n",
            "Ep 2 (Step 000010): Train loss 6.753, Val loss 7.048\n",
            "Ep 2 (Step 000015): Train loss 6.114, Val loss 6.573\n",
            "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
            "Ep 3 (Step 000020): Train loss 5.525, Val loss 6.490\n",
            "Ep 3 (Step 000025): Train loss 5.324, Val loss 6.387\n",
            "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
            "Ep 4 (Step 000030): Train loss 4.761, Val loss 6.360\n",
            "Ep 4 (Step 000035): Train loss 4.461, Val loss 6.258\n",
            "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
            "Ep 5 (Step 000040): Train loss 3.833, Val loss 6.196\n",
            "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
            "Ep 6 (Step 000045): Train loss 3.352, Val loss 6.139\n",
            "Ep 6 (Step 000050): Train loss 2.861, Val loss 6.112\n",
            "Every effort moves you know; and my dear, and he was not the fact with a little of the house of the fact of the fact, and.                       \n",
            "Ep 7 (Step 000055): Train loss 2.347, Val loss 6.138\n",
            "Ep 7 (Step 000060): Train loss 2.084, Val loss 6.179\n",
            "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I looked--as of the fact, and I felt him--his back his head to the donkey. \"Oh, and_--because he had always _\n",
            "Ep 8 (Step 000065): Train loss 1.521, Val loss 6.176\n",
            "Ep 8 (Step 000070): Train loss 1.272, Val loss 6.178\n",
            "Every effort moves you?\" \"I didn't bear the picture--I told me.  \"I looked up, and went on groping and Mrs. I was back the head to look up at the honour being _mine_--because he was when I\n",
            "Ep 9 (Step 000075): Train loss 1.000, Val loss 6.277\n",
            "Ep 9 (Step 000080): Train loss 0.718, Val loss 6.281\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
            "Ep 10 (Step 000085): Train loss 0.506, Val loss 6.325\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n",
            "Training completed in 21.78 minutes.\n"
          ]
        }
      ],
      "source": [
        "# Note:\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Note:\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iORIB-FftXP7"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "As we can see, based on the results printed during the training, the training loss improves\n",
        "drastically, starting with a value of 9.781 and converging to 0.391.\n",
        "\n",
        "The language skills of\n",
        "the model have improved quite a lot. In the beginning, the model is only able to append\n",
        "commas to the start context (\"Every effort moves you,,,,,,,,,,,,\") or repeat the\n",
        "word \"and\".\n",
        "\n",
        "At the end of the training, it can generate grammatically correct text.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN5aUBCStXP7"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "Similar to the training set loss, we can see that the validation loss starts high (9.856)\n",
        "and decreases during the training.\n",
        "\n",
        "However, it never becomes as small as the training set\n",
        "loss and remains at 6.372 after the 10th epoch.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPiPMoQFtXP7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's create a simple plot that shows the training and validation set losses side by side\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "WXlljIrPtXP7",
        "outputId": "0ac1a81f-e2d5-4ca9-b3ed-685f706fca44"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-_3NdbctXP8"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Both the training and validation losses start to improve for the first\n",
        "epoch. However, the losses start to diverge past the second epoch.\n",
        "\n",
        "This divergence and the\n",
        "fact that the validation loss is much larger than the training loss indicate that the model is\n",
        "overfitting to the training data.\n",
        "\n",
        "We can confirm that the model memorizes the training data\n",
        "verbatim by searching for the generated text snippets, such as \"quite insensible to the\n",
        "irony\" in the \"The Verdict\" text file.\n",
        "\n",
        "\n",
        "This memorization is expected since we are working with a very, very small training\n",
        "dataset and training the model for multiple epochs.\n",
        "\n",
        "Usually, it's common to train a model\n",
        "on a much, much larger dataset for only one epoch.   \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xL3eiOV91cQD"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNB0fetW0DLzUdx4u1hfUHy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}