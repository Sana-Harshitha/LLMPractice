{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMW3HT02VaPpg2Wd3rrlZg4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sana-Harshitha/LLMPractice/blob/main/positional_encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "PC4mtvjqtB68"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        "\"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        "\"the-verdict.txt\")\n",
        "file_path = \"the-verdict.txt\"\n",
        "urllib.request.urlretrieve(url, file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpd0_5g8tyDl",
        "outputId": "674a8cc9-4c08-4cb4-c4cf-f276452edb2b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('the-verdict.txt', <http.client.HTTPMessage at 0x7d2a196b20d0>)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "   raw_text = f.read()\n",
        "print(\"Total number of character:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRSxrY5Dt2CC",
        "outputId": "4bb9c68d-7941-426f-b0d4-46e87891abb3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of character: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#generating INPUT-OUTPUT target pairs"
      ],
      "metadata": {
        "id": "dmGuaNnewjGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDatasetV1(Dataset):\n",
        "   def __init__(self, txt, tokenizer, max_length, stride):\n",
        "         self.input_ids = []\n",
        "         self.target_ids = []\n",
        "         token_ids = tokenizer.encode(txt)\n",
        "         for i in range(0, len(token_ids) - max_length, stride):\n",
        "              input_chunk = token_ids[i:i + max_length]\n",
        "              target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "              self.input_ids.append(torch.tensor(input_chunk))\n",
        "              self.target_ids.append(torch.tensor(target_chunk))\n",
        "   def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "   def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "oIXqbt8Gudne"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "          stride=128, shuffle=True, drop_last=True,\n",
        "          num_workers=0):\n",
        "          tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "          dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "          dataloader = DataLoader(\n",
        "                           dataset,\n",
        "                           batch_size=batch_size,\n",
        "                           shuffle=shuffle,\n",
        "                           drop_last=drop_last,\n",
        "                           num_workers=num_workers\n",
        "                                   )\n",
        "          return dataloader"
      ],
      "metadata": {
        "id": "nQkGOTPevF_M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6DvRhfe_pfep"
      },
      "outputs": [],
      "source": [
        "vocab_size=50257\n",
        "output_dim=256"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embedding_layer=torch.nn.Embedding(vocab_size,output_dim)"
      ],
      "metadata": {
        "id": "ArbKyyxvsyrj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length=4\n",
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:raw_text = f.read()\n",
        "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=max_length, stride=max_length, shuffle=False)\n",
        "data_iter = iter(dataloader)\n",
        "inputs,targets = next(data_iter)\n",
        "print(inputs.shape)\n",
        "print(targets.shape)"
      ],
      "metadata": {
        "id": "OX-YUAvUtJji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f86b2bad-3484-40e0-a434-98634abc2de6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4])\n",
            "torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"first input batch: \",inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-PlNRuZ2l2U",
        "outputId": "23dd4341-a599-4143-c502-f388812c7273"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first input batch:  tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings=token_embedding_layer(inputs)\n",
        "token_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc2plB6X2-SZ",
        "outputId": "48614c29-4772-405c-e4df-af7f93511af4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 4, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length=max_length\n",
        "pos_embedding_layer=torch.nn.Embedding(context_length,output_dim)"
      ],
      "metadata": {
        "id": "oI_LAVOe5r1D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_embeddings=pos_embedding_layer(torch.arange(max_length))\n",
        "pos_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0qYZNqm8Sn1",
        "outputId": "f00fea3f-1734-4b2a-fd61-582a6a40fff0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_embeddings=token_embeddings+pos_embeddings\n",
        "input_embeddings.shape"
      ],
      "metadata": {
        "id": "KDLw9Qay8rbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings"
      ],
      "metadata": {
        "id": "enOpbOui_xVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rJ1cRtclAayQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}